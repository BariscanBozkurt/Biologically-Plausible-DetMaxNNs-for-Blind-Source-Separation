{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13b17f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import pylab as pl\n",
    "\n",
    "from WSMBSS import *\n",
    "from general_utils import *\n",
    "from visualization_utils import * \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "notebook_name = 'Nonnegative_Antisparse_Copula'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e411b25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def run_neural_dynamics_nnantisparse_jit(x_current, h, y, M_H, M_Y, W_HX, W_YH, D1, D2, beta, zeta, \n",
    "                                         neural_dynamic_iterations, lr_start, lr_stop, \n",
    "                                         lr_rule, lr_decay_multiplier = 0.01, hidden_layer_gain = 2, \n",
    "                                         use_hopfield = True, OUTPUT_COMP_TOL = 1e-7):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        x_current (_type_): _description_\n",
    "        h (_type_): _description_\n",
    "        y (_type_): _description_\n",
    "        M_H (_type_): _description_\n",
    "        M_Y (_type_): _description_\n",
    "        W_HX (_type_): _description_\n",
    "        W_YH (_type_): _description_\n",
    "        D1 (_type_): _description_\n",
    "        D2 (_type_): _description_\n",
    "        beta (_type_): _description_\n",
    "        zeta (_type_): _description_\n",
    "        neural_dynamic_iterations (_type_): _description_\n",
    "        lr_start (_type_): _description_\n",
    "        lr_stop (_type_): _description_\n",
    "        OUTPUT_COMP_TOL (_type_): _description_\n",
    "    \"\"\"\n",
    "    def offdiag(A, return_diag = False):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            A (_type_): _description_\n",
    "            return_diag (bool, optional): _description_. Defaults to False.\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"\n",
    "        if return_diag:\n",
    "            diag = np.diag(A)\n",
    "            return A - np.diag(diag), diag\n",
    "        else:\n",
    "            return A - np.diag(diag)\n",
    "\n",
    "    M_hat_H, Gamma_H = offdiag(M_H, True)\n",
    "    M_hat_Y, Gamma_Y = offdiag(M_Y, True)\n",
    "\n",
    "    mat_factor1 = (1 - zeta) * beta * (D1 * W_HX)\n",
    "    mat_factor2 = ((1 - zeta) * (1 - beta) * M_hat_H  + (1- zeta) * beta * ((D1 * M_hat_H) * D1.T))\n",
    "    mat_factor3 = (1 - zeta) * (1 - beta) * (W_YH.T * D2.T)\n",
    "    mat_factor4 = (1 - zeta) * Gamma_H * ((1 - beta) + beta * (D1.T) ** 2)\n",
    "    mat_factor5 = M_hat_Y * D2.T\n",
    "    mat_factor6 = Gamma_Y * D2.T\n",
    "\n",
    "    v = mat_factor4[0] * h\n",
    "    u = mat_factor6[0] * y\n",
    "\n",
    "    PreviousMembraneVoltages = {'v': np.zeros_like(v), 'u': np.zeros_like(u)}\n",
    "    MembraneVoltageNotSettled = 1\n",
    "    OutputCounter = 0\n",
    "    while MembraneVoltageNotSettled & (OutputCounter < neural_dynamic_iterations):\n",
    "        OutputCounter += 1\n",
    "        if lr_rule == \"constant\":\n",
    "            MUV = lr_start\n",
    "        elif lr_rule == \"divide_by_loop_index\":\n",
    "            MUV = max(lr_start/(1+OutputCounter), lr_stop)\n",
    "        elif lr_rule == \"divide_by_slow_loop_index\":\n",
    "            MUV = max(lr_start/(1+OutputCounter*lr_decay_multiplier), lr_stop)\n",
    "\n",
    "        delv = -v + mat_factor1 @ x_current - mat_factor2 @ h + mat_factor3 @ y\n",
    "        v = v + MUV * delv\n",
    "        h = v / mat_factor4[0]\n",
    "        h = np.clip(h, -hidden_layer_gain, hidden_layer_gain)\n",
    "        delu = -u + W_YH @ h - mat_factor5 @ y\n",
    "        u = u + MUV * delu\n",
    "        y = u / mat_factor6[0]\n",
    "        y = np.clip(y, 0, 1)\n",
    "\n",
    "        MembraneVoltageNotSettled = 0\n",
    "        if (np.linalg.norm(v - PreviousMembraneVoltages['v'])/np.linalg.norm(v) > OUTPUT_COMP_TOL) | (np.linalg.norm(u - PreviousMembraneVoltages['u'])/np.linalg.norm(u) > OUTPUT_COMP_TOL):\n",
    "            MembraneVoltageNotSettled = 1\n",
    "        PreviousMembraneVoltages['v'] = v\n",
    "        PreviousMembraneVoltages['u'] = u\n",
    "\n",
    "    return h,y, OutputCounter\n",
    "\n",
    "@njit\n",
    "def update_weights_jit(x_current, h, y, zeta, beta, W_HX, W_YH, M_H, M_Y, D1, D2, \n",
    "                       MU_MH, MU_MY, MU_WHX, MU_WYH, muD, LayerMinimumGains, \n",
    "                       LayerMaximumGains, clip_gain_gradients = False):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        x_current (_type_): _description_\n",
    "        h (_type_): _description_\n",
    "        y (_type_): _description_\n",
    "        zeta (_type_): _description_\n",
    "        beta (_type_): _description_\n",
    "        W_HX (_type_): _description_\n",
    "        W_YH (_type_): _description_\n",
    "        M_H (_type_): _description_\n",
    "        M_Y (_type_): _description_\n",
    "        D1 (_type_): _description_\n",
    "        D2 (_type_): _description_\n",
    "        MUS (_type_): _description_\n",
    "        muD (_type_): _description_\n",
    "        LayerMinimumGains (_type_): _description_\n",
    "        LayerMaximumGains (_type_): _description_\n",
    "    \"\"\"\n",
    "    def clipping(inp,lev):\n",
    "        out=inp*(np.abs(inp)<=lev)+lev*(inp>lev)-lev*(inp<-lev)\n",
    "        return out\n",
    "\n",
    "    M_H = (1 - MU_MH) * M_H + MU_MH * np.outer(h,h)\n",
    "    W_HX = (1 - MU_WHX) * W_HX + MU_WHX * np.outer(h,x_current)\n",
    "\n",
    "    M_Y = (1 - MU_MY) * M_Y + MU_MY * np.outer(y,y)\n",
    "    W_YH = (1 - MU_WYH) * W_YH + MU_WYH * np.outer(y,h)\n",
    "\n",
    "    D1derivative = (1 - zeta) * beta * (np.sum((np.abs(M_H)**2) * D1.T,axis=1) - np.sum(np.abs(W_HX)**2,axis=1)).reshape(-1,1)  + zeta * (1/D1)#+ zeta * self.dlogdet(D1)\n",
    "    if clip_gain_gradients:\n",
    "        D1 = D1 - clipping(muD[0] * D1derivative, D1 * 1)\n",
    "    else:\n",
    "        D1 = D1 - muD[0] * D1derivative\n",
    "    D1 = np.clip(D1, LayerMinimumGains[0], LayerMaximumGains[0])\n",
    "    D2derivative = (1 - zeta) * (1 - beta) * (np.sum((np.abs(M_Y)**2) * D2.T,axis=1) - np.sum(np.abs(W_YH)**2,axis=1)).reshape(-1,1)  + zeta * (1/D2)#+ zeta * self.dlogdet(D2)\n",
    "    if clip_gain_gradients:\n",
    "        D2 = D2 - clipping(muD[1] * D2derivative, D2 * 1) \n",
    "    else:\n",
    "        D2 = D2 - muD[1] * D2derivative\n",
    "    D2 = np.clip(D2, LayerMinimumGains[1], LayerMaximumGains[1])\n",
    "    return W_HX, W_YH, M_H, M_Y, D1, D2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72954bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following is the mixture matrix A\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\begin{bmatrix} \n",
       " 0.147 & -0.255 & -0.599 & 1.069 & -0.646 & \\\\\n",
       " 0.141 & -0.504 & -0.437 & -0.465 & 0.407 & \\\\\n",
       " -0.910 & 0.543 & 0.112 & -0.587 & 0.005 & \\\\\n",
       " 0.137 & 0.066 & -0.820 & -0.290 & -0.074 & \\\\\n",
       " -0.151 & 0.008 & -0.687 & -0.365 & -0.033 & \\\\\n",
       " -0.214 & 0.304 & -0.100 & 0.816 & 0.211 & \\\\\n",
       " 0.281 & 0.576 & 0.452 & -0.267 & -0.139 & \\\\\n",
       " -0.470 & -0.262 & -0.302 & -0.384 & 0.545 & \\\\\n",
       " -0.042 & 0.195 & 0.336 & 0.703 & -0.819 & \\\\\n",
       " -0.779 & -0.382 & 0.171 & -0.033 & 0.092 & \\\\\n",
       "\\end{bmatrix}$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input SNR is : 29.99847169729263\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(100)\n",
    "rho = 0.5\n",
    "N = 500000\n",
    "NumberofSources = 5\n",
    "NumberofMixtures = 10\n",
    "\n",
    "# NoiseAmp = (10 ** (-SNR/20))# * np.sqrt(NumberofSources)\n",
    "\n",
    "S = generate_correlated_copula_sources(rho = rho, df = 4, n_sources = NumberofSources, size_sources = N , \n",
    "                                       decreasing_correlation = True)\n",
    "\n",
    "INPUT_STD = 0.28\n",
    "A, X = WSM_Mixing_Scenario(S, NumberofMixtures, INPUT_STD)\n",
    "\n",
    "SNR=30\n",
    "X, NoisePart = addWGN(X, SNR, return_noise = True)\n",
    "\n",
    "SNRinp = 10 * np.log10(np.sum(np.mean((X - NoisePart)**2, axis = 1)) / np.sum(np.mean(NoisePart**2, axis = 1)))\n",
    "print(\"The following is the mixture matrix A\")\n",
    "display_matrix(A)\n",
    "print(\"Input SNR is : {}\".format(SNRinp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9234d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "if rho > 0.4:\n",
    "    gamma_start = 0.05\n",
    "    gamma_stop = 5*1e-4\n",
    "else:\n",
    "    gamma_start = 0.1\n",
    "    gamma_stop = 1e-3\n",
    "    \n",
    "gammaM_start = [gamma_start, gamma_start]\n",
    "gammaM_stop = [gamma_stop, gamma_stop]\n",
    "gammaW_start = [gamma_start, gamma_start]\n",
    "gammaW_stop = [gamma_stop, gamma_stop]\n",
    "\n",
    "OUTPUT_COMP_TOL = 1e-7\n",
    "LayerGains = np.array([1,1])\n",
    "LayerMinimumGains = np.array([1e-3,1e-3])\n",
    "LayerMaximumGains = np.array([1e6,20])\n",
    "WScalings = [0.0033,0.0033]\n",
    "GamScalings = [2,1]\n",
    "zeta = 1*1e-5\n",
    "beta = 0.5\n",
    "muD = np.array([1, 1e-2])\n",
    "\n",
    "neural_dynamic_iterations = 500\n",
    "neural_lr_start = 0.75\n",
    "neural_lr_stop = 0.05\n",
    "neural_lr_rule = \"divide_by_slow_loop_index\"\n",
    "synaptic_lr_decay_divider = 1\n",
    "lr_decay_multiplier = 0.005\n",
    "hidden_layer_gain = 200\n",
    "use_hopfield = True\n",
    "clip_gain_gradients = True\n",
    "s_dim = S.shape[0]\n",
    "x_dim = X.shape[0]\n",
    "h_dim = s_dim\n",
    "samples = S.shape[1]\n",
    "W_HX = np.eye(h_dim, x_dim)\n",
    "W_YH = np.eye(s_dim, h_dim)\n",
    "M_H = GamScalings[0] * np.eye(h_dim)\n",
    "M_Y = GamScalings[1] * np.eye(s_dim)\n",
    "D1 = LayerGains[0] * np.ones((h_dim, 1))\n",
    "D2 = LayerGains[1] * np.ones((s_dim, 1))\n",
    "\n",
    "H = np.zeros((h_dim,samples))\n",
    "Y = np.zeros((s_dim,samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27dc0982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.07172723, -0.12295662, -0.22121069, -0.05889156, -0.14912889]),\n",
       " array([0.07172721, 0.        , 0.        , 0.        , 0.        ]),\n",
       " 25)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_sample = 0\n",
    "x_current = X[:, i_sample]\n",
    "h = H[:, i_sample]\n",
    "y = Y[:, i_sample]\n",
    "\n",
    "h,y, oc = run_neural_dynamics_nnantisparse_jit(x_current, h, y, M_H, M_Y, W_HX, W_YH, D1, D2, beta, zeta, \n",
    "                                         neural_dynamic_iterations, neural_lr_start, neural_lr_stop, \n",
    "                                         neural_lr_rule, lr_decay_multiplier, hidden_layer_gain, \n",
    "                                         use_hopfield, OUTPUT_COMP_TOL)\n",
    "h,y, oc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e2b9c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MU_MH = np.max([gammaM_start[0]/(1 + np.log(1 + (i_sample//synaptic_lr_decay_divider))/10), gammaM_stop[0]])\n",
    "MU_MY = np.max([gammaM_start[1]/(1 + np.log(1 + (i_sample//synaptic_lr_decay_divider))/10), gammaM_stop[1]])\n",
    "MU_WHX = np.max([gammaW_start[0]/(1 + np.log(1 + (i_sample//synaptic_lr_decay_divider))/10), gammaW_stop[0]])\n",
    "MU_WYH = np.max([gammaW_start[1]/(1 + np.log(1 + (i_sample//synaptic_lr_decay_divider))/10), gammaW_stop[1]])\n",
    "W_HX, W_YH, M_H, M_Y, D1, D2 = update_weights_jit( x_current, h, y, zeta, beta, W_HX, W_YH, M_H, M_Y, D1, D2, \n",
    "                                                   MU_MH, MU_MY, MU_WHX, MU_WYH, muD, LayerMinimumGains, \n",
    "                                                   LayerMaximumGains, clip_gain_gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1467536c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.50771720e-01, -1.76386744e-03, -3.17336589e-03,\n",
       "        -8.44825635e-04, -2.13932029e-03,  3.72749260e-03,\n",
       "         1.96563602e-03, -2.34090290e-03,  4.21589966e-04,\n",
       "        -3.79112546e-03],\n",
       "       [-1.32290104e-03,  9.53023666e-01,  5.43986370e-03,\n",
       "         1.44822137e-03,  3.66727670e-03, -6.38976167e-03,\n",
       "        -3.36954275e-03,  4.01283468e-03, -7.22700134e-04,\n",
       "         6.49884271e-03],\n",
       "       [-2.38002525e-03,  5.43986370e-03,  9.59786834e-01,\n",
       "         2.60548849e-03,  6.59778084e-03, -1.14957912e-02,\n",
       "        -6.06212904e-03,  7.21947263e-03, -1.30020653e-03,\n",
       "         1.16920384e-02],\n",
       "       [-6.33619448e-04,  1.44822137e-03,  2.60548849e-03,\n",
       "         9.50693643e-01,  1.75648652e-03, -3.06045361e-03,\n",
       "        -1.61388324e-03,  1.92199569e-03, -3.46145967e-04,\n",
       "         3.11269929e-03],\n",
       "       [-1.60449078e-03,  3.66727670e-03,  6.59778084e-03,\n",
       "         1.75648652e-03,  9.54447885e-01, -7.74987195e-03,\n",
       "        -4.08677603e-03,  4.86699764e-03, -8.76532458e-04,\n",
       "         7.88217174e-03]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_HX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c29d46d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(D1 - LayerMinimumGains[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d4b459",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
