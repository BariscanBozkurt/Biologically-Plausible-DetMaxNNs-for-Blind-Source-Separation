{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7f35e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "os.chdir(\"..\")\n",
    "os.chdir(\"..\")\n",
    "os.chdir(\"./src\")\n",
    "# sys.path.append(\"./src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1f4de15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import invgamma, chi2, t\n",
    "from WSMBSS import *\n",
    "from numba import njit\n",
    "from IPython import display\n",
    "import pylab as pl\n",
    "import mne \n",
    "from mne.preprocessing import ICA\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(1569)\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "notebook_name = 'Antisparse_Copula'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d34826e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following is the mixture matrix A\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\begin{bmatrix} \n",
       " 0.059 & 0.644 & 0.220 & 0.090 & \\\\\n",
       " 0.422 & 0.313 & 0.188 & 0.211 & \\\\\n",
       " 0.210 & -0.923 & 0.514 & 0.502 & \\\\\n",
       " 0.902 & -0.226 & 0.147 & -0.472 & \\\\\n",
       " -0.402 & -0.531 & -0.049 & -0.033 & \\\\\n",
       " 0.256 & -0.299 & 0.508 & 0.513 & \\\\\n",
       " -0.114 & 0.856 & -1.097 & 0.209 & \\\\\n",
       " -0.262 & -0.562 & 0.029 & -0.297 & \\\\\n",
       "\\end{bmatrix}$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input SNR is : 30.002407782786484\n"
     ]
    }
   ],
   "source": [
    "rho = 0.6\n",
    "N = 500000\n",
    "NumberofSources = 4\n",
    "NumberofMixtures = 8\n",
    "\n",
    "M = NumberofMixtures\n",
    "r = NumberofSources\n",
    "\n",
    "SNR = 30 # dB\n",
    "NoiseAmp = (10 ** (-SNR/20))# * np.sqrt(NumberofSources)\n",
    "\n",
    "S = generate_correlated_copula_sources(rho = rho, df = 4, n_sources = NumberofSources, size_sources = N , \n",
    "                                       decreasing_correlation = True)\n",
    "S = 2 * S - 1\n",
    "INPUT_STD = 0.5\n",
    "A = np.random.standard_normal(size=(NumberofMixtures,NumberofSources))\n",
    "X = A @ S\n",
    "for MM in range(A.shape[0]):\n",
    "    stdx = np.std(X[MM,:])\n",
    "    A[MM,:] = A[MM,:]/stdx * INPUT_STD\n",
    "Xn = A @ S\n",
    "Noisecomp=np.random.randn(A.shape[0],S.shape[1])*np.power(10,-SNR/20)*INPUT_STD\n",
    "X=Xn+Noisecomp\n",
    "SNRinp = 20*np.log10(np.std(Xn)/np.std(Noisecomp))\n",
    "\n",
    "print(\"The following is the mixture matrix A\")\n",
    "display_matrix(A)\n",
    "print(\"Input SNR is : {}\".format(SNRinp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6180067",
   "metadata": {},
   "outputs": [],
   "source": [
    "if rho > 0.4:\n",
    "    MUS = 0.25\n",
    "    gamma_stop = 5*1e-4\n",
    "else:\n",
    "    MUS = 0.6\n",
    "    gamma_stop = 1e-3\n",
    "OUTPUT_COMP_TOL = 1e-6\n",
    "MAX_OUT_ITERATIONS= 3000\n",
    "LayerGains = [1,1]\n",
    "LayerMinimumGains = [0.2,0.2]\n",
    "LayerMaximumGains = [1e6,5]\n",
    "WScalings = [0.005,0.005]\n",
    "GamScalings = [2,1]\n",
    "zeta = 5*1e-5\n",
    "beta = 0.5\n",
    "muD = [1.125, 0.2]\n",
    "\n",
    "s_dim = S.shape[0]\n",
    "x_dim = X.shape[0]\n",
    "h_dim = s_dim\n",
    "samples = S.shape[1]\n",
    "W_HX = np.eye(h_dim, x_dim)\n",
    "W_YH = np.eye(s_dim, h_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4331d386",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_iteration_point = 10000\n",
    "model = OnlineWSMBSS(s_dim = s_dim, x_dim = x_dim, h_dim = h_dim, \n",
    "                        gamma_start = MUS, gamma_stop = gamma_stop, beta = beta, zeta = zeta, \n",
    "                        muD = muD,WScalings = WScalings, GamScalings = GamScalings,\n",
    "                        W_HX = W_HX, W_YH = W_YH,\n",
    "                        DScalings = LayerGains, LayerMinimumGains = LayerMinimumGains,\n",
    "                        LayerMaximumGains = LayerMaximumGains,neural_OUTPUT_COMP_TOL = OUTPUT_COMP_TOL,\n",
    "                        set_ground_truth = True, S = S, A = A)\n",
    "\n",
    "# modelWSM.fit_batch_antisparse(X, n_epochs = 1, \n",
    "#                                 neural_lr_start = 0.75,\n",
    "#                                 neural_lr_stop = 0.05,\n",
    "#                                 debug_iteration_point = debug_iteration_point,\n",
    "#                                 plot_in_jupyter = True,\n",
    "#                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05e87ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def run_neural_dynamics_antisparse_jitV4(x_current, h, y, M_H, M_Y, W_HX, W_YH, D1, D2, beta, zeta, \n",
    "                                         neural_dynamic_iterations, lr_start, lr_stop, OUTPUT_COMP_TOL):\n",
    "    \n",
    "    def ddiag(A):\n",
    "        return np.diag(np.diag(A))\n",
    "    \n",
    "    def offdiag(A, return_diag = False):\n",
    "        if return_diag:\n",
    "            diag = np.diag(A)\n",
    "            return A - np.diag(diag), diag\n",
    "        else:\n",
    "            return A - np.diag(diag)\n",
    "    \n",
    "    M_hat_H, Gamma_H = offdiag(M_H, True)\n",
    "    M_hat_Y, Gamma_Y = offdiag(M_Y, True)\n",
    "    \n",
    "    mat_factor1 = (1 - zeta) * beta * (D1 * W_HX)\n",
    "    mat_factor2 = ((1 - zeta) * (1 - beta) * M_hat_H  + (1- zeta) * beta * ((D1 * M_hat_H) * D1.T))\n",
    "    mat_factor3 = (1 - zeta) * (1 - beta) * (W_YH.T * D2.T)\n",
    "    mat_factor4 = (1 - zeta) * Gamma_H * ((1 - beta) + beta * D1 ** 2)\n",
    "    mat_factor5 = M_hat_Y * D2.T\n",
    "    mat_factor6 = Gamma_Y * D2\n",
    "    \n",
    "\n",
    "    v = mat_factor4 @ h\n",
    "    u = mat_factor6 @ y\n",
    "    \n",
    "    PreviousMembraneVoltages = {'v': np.zeros_like(v), 'u': np.zeros_like(u)}\n",
    "    MembraneVoltageNotSettled = 1\n",
    "    OutputCounter = 0\n",
    "    while MembraneVoltageNotSettled & (OutputCounter < neural_dynamic_iterations):\n",
    "        OutputCounter += 1\n",
    "        MUV = max(lr_start/(1+OutputCounter*0.005), lr_stop)\n",
    "\n",
    "        delv = -v + mat_factor1 @ x_current - mat_factor2 @ h + mat_factor3 @ y\n",
    "        v = v + MUV * delv\n",
    "        h = v / np.diag(mat_factor4)\n",
    "\n",
    "        delu = -u + W_YH @ h - mat_factor5 @ y\n",
    "        u = u + MUV * delu\n",
    "        y = u / np.diag(mat_factor6)\n",
    "        y = np.clip(y, -1, 1)\n",
    "\n",
    "        MembraneVoltageNotSettled = 0\n",
    "        if (np.linalg.norm(v - PreviousMembraneVoltages['v'])/np.linalg.norm(v) > OUTPUT_COMP_TOL) | (np.linalg.norm(u - PreviousMembraneVoltages['u'])/np.linalg.norm(u) > OUTPUT_COMP_TOL):\n",
    "            MembraneVoltageNotSettled = 1\n",
    "        PreviousMembraneVoltages['v'] = v\n",
    "        PreviousMembraneVoltages['u'] = u\n",
    "\n",
    "    return h,y, OutputCounter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "502b4d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_HX = model.W_HX\n",
    "W_YH = model.W_YH\n",
    "M_H = model.M_H\n",
    "M_Y = model.M_Y\n",
    "D1 = model.D1\n",
    "D2 = model.D2\n",
    "d1 = np.diag(D1).reshape(-1,1)\n",
    "d2 = np.diag(D2).reshape(-1,1)\n",
    "neural_dynamic_iterations = 750\n",
    "lr_start = 0.75\n",
    "lr_stop = 0.05\n",
    "OUTPUT_COMP_TOL = 1e-6\n",
    "\n",
    "def ddiag(A):\n",
    "    return np.diag(np.diag(A))\n",
    "\n",
    "Gamma_H = ddiag(M_H)\n",
    "M_hat_H = M_H - Gamma_H\n",
    "\n",
    "Gamma_Y = ddiag(M_Y)\n",
    "M_hat_Y = M_Y - Gamma_Y\n",
    "    \n",
    "    \n",
    "H = np.zeros((h_dim,samples))\n",
    "Y = np.zeros((s_dim,samples))\n",
    "\n",
    "x_current  = X[:,0] # Take one input\n",
    "\n",
    "y = Y[:,0]\n",
    "\n",
    "h = H[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c0b5ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "h4,y4,_ =run_neural_dynamics_antisparse_jitV4(x_current, h, y, M_H, M_Y, W_HX, W_YH, d1, d2, beta, zeta, \n",
    "                                    neural_dynamic_iterations, lr_start, lr_stop, OUTPUT_COMP_TOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "833e5f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(x_current, h, y, zeta, beta, W_HX, W_YH, M_H, M_Y, D1, D2, MUS, muD, LayerMinimumGains, LayerMaximumGains ):\n",
    "    M_H = (1 - MUS) * M_H + MUS * np.outer(h,h)\n",
    "    W_HX = (1 - MUS) * W_HX + MUS * np.outer(h,x_current)\n",
    "\n",
    "    M_Y = (1 - MUS) * M_Y + MUS * np.outer(y,y)\n",
    "    W_YH = (1 - MUS) * W_YH + MUS * np.outer(y,h)\n",
    "\n",
    "    D1derivative = (1 - zeta) * beta * np.diag(np.diag(M_H @ D1 @ M_H - W_HX @ W_HX.T)) + zeta * model.dlogdet(D1)\n",
    "    D1 = D1 - muD[0] * D1derivative\n",
    "\n",
    "    D2derivative = (1 - zeta) * (1 - beta) * np.diag(np.diag(M_Y @ D2 @ M_Y - W_YH @ W_YH.T)) + zeta * model.dlogdet(D2)\n",
    "    D2 = D2 - muD[1] * D2derivative\n",
    "\n",
    "    d1 = np.diag(D1)\n",
    "    d2 = np.diag(D2)\n",
    "\n",
    "    D1 = np.diag(d1 * (d1 > LayerMinimumGains[0]) * (d1 < LayerMaximumGains[0]) + LayerMaximumGains[0] * (d1 >= LayerMaximumGains[0]) + LayerMinimumGains[0] * (d1 <= LayerMinimumGains[0]))\n",
    "    D2 = np.diag(d2 * (d2 > LayerMinimumGains[1]) * (d2 < LayerMaximumGains[1]) + LayerMaximumGains[1] * (d2 >= LayerMaximumGains[1]) + LayerMinimumGains[1] * (d2 <= LayerMinimumGains[1]))\n",
    "    return W_HX, W_YH, M_H, M_Y, D1, D2\n",
    "\n",
    "@njit\n",
    "def update_weights_jit(x_current, h, y, zeta, beta, W_HX, W_YH, M_H, M_Y, D1, D2, MUS, muD, LayerMinimumGains, LayerMaximumGains ):\n",
    "#     if isinstance(LayerMinimumGains,list):\n",
    "#         LayerMinimumGains = np.array(LayerMinimumGains)\n",
    "#     if isinstance(LayerMaximumGains,list):\n",
    "#         LayerMaximumGains = np.array(LayerMaximumGains)\n",
    "    M_H = (1 - MUS) * M_H + MUS * np.outer(h,h)\n",
    "    W_HX = (1 - MUS) * W_HX + MUS * np.outer(h,x_current)\n",
    "\n",
    "    M_Y = (1 - MUS) * M_Y + MUS * np.outer(y,y)\n",
    "    W_YH = (1 - MUS) * W_YH + MUS * np.outer(y,h)\n",
    "\n",
    "    D1derivative = (1 - zeta) * beta * (np.sum((np.abs(M_H)**2) * D1.T,axis=1) - np.sum(np.abs(W_HX)**2,axis=1)).reshape(-1,1)  + zeta * (1/D1)#+ zeta * self.dlogdet(D1)\n",
    "    D1 = D1 - muD[0] * D1derivative\n",
    "    D1 = np.clip(D1, LayerMinimumGains[0], LayerMaximumGains[0])\n",
    "    D2derivative = (1 - zeta) * (1 - beta) * (np.sum((np.abs(M_Y)**2) * D2.T,axis=1) - np.sum(np.abs(W_YH)**2,axis=1)).reshape(-1,1)  + zeta * (1/D2)#+ zeta * self.dlogdet(D2)\n",
    "    D2 = D2 - muD[1] * D2derivative\n",
    "    D2 = np.clip(D2, LayerMinimumGains[1], LayerMaximumGains[1])\n",
    "    return W_HX, W_YH, M_H, M_Y, D1, D2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04081ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_HX_1, W_YH_1, M_H_1, M_Y_1, D1_1, D2_1 = update_weights(x_current, h, y, zeta, beta, W_HX, W_YH, M_H, M_Y, D1, D2, MUS, muD, LayerMinimumGains, LayerMaximumGains )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d28c04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_HX_2, W_YH_2, M_H_2, M_Y_2, D1_2, D2_2 = update_weights_jit(x_current, h, y, zeta, beta, W_HX, W_YH, M_H, M_Y, d1, d2, MUS, muD, np.array(LayerMinimumGains), np.array(LayerMaximumGains) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6962f5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.0, 0.0, 0.0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(W_HX_1 - W_HX_2),np.linalg.norm(W_YH_1 - W_YH_2),np.linalg.norm(M_H_1 - M_H_2),np.linalg.norm(M_Y_1 - M_Y_2),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "879efc35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]]),\n",
       " array([[4.99933428e-13],\n",
       "        [4.99933428e-13],\n",
       "        [4.99933428e-13],\n",
       "        [4.99933428e-13]]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.diag(D1_1).reshape(-1,1) - D1_2, np.diag(D2_1).reshape(-1,1) - D2_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0f70cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108 µs ± 7.23 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit update_weights(x_current, h, y, zeta, beta, W_HX, W_YH, M_H, M_Y, D1, D2, MUS, muD,  LayerMinimumGains, LayerMaximumGains )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36aa3869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 µs ± 3.58 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit update_weights_jit(x_current, h, y, zeta, beta, W_HX, W_YH, M_H, M_Y, d1, d2, MUS, muD , np.array(LayerMinimumGains), np.array(LayerMaximumGains) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ec3fbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit( parallel=True )\n",
    "def update_weights_jit_parallel(x_current, h, y, zeta, beta, W_HX, W_YH, M_H, M_Y, D1, D2, MUS, muD, LayerMinimumGains, LayerMaximumGains ):\n",
    "#     if isinstance(LayerMinimumGains,list):\n",
    "#         LayerMinimumGains = np.array(LayerMinimumGains)\n",
    "#     if isinstance(LayerMaximumGains,list):\n",
    "#         LayerMaximumGains = np.array(LayerMaximumGains)\n",
    "    M_H = (1 - MUS) * M_H + MUS * np.outer(h,h)\n",
    "    W_HX = (1 - MUS) * W_HX + MUS * np.outer(h,x_current)\n",
    "\n",
    "    M_Y = (1 - MUS) * M_Y + MUS * np.outer(y,y)\n",
    "    W_YH = (1 - MUS) * W_YH + MUS * np.outer(y,h)\n",
    "\n",
    "    D1derivative = (1 - zeta) * beta * (np.sum((np.abs(M_H)**2) * D1.T,axis=1) - np.sum(np.abs(W_HX)**2,axis=1)).reshape(-1,1)  + zeta * (1/D1)#+ zeta * self.dlogdet(D1)\n",
    "    D1 = D1 - muD[0] * D1derivative\n",
    "    D1 = np.clip(D1, LayerMinimumGains[0], LayerMaximumGains[0])\n",
    "    D2derivative = (1 - zeta) * (1 - beta) * (np.sum((np.abs(M_Y)**2) * D2.T,axis=1) - np.sum(np.abs(W_YH)**2,axis=1)).reshape(-1,1)  + zeta * (1/D2)#+ zeta * self.dlogdet(D2)\n",
    "    D2 = D2 - muD[1] * D2derivative\n",
    "    D2 = np.clip(D2, LayerMinimumGains[1], LayerMaximumGains[1])\n",
    "    return W_HX, W_YH, M_H, M_Y, D1, D2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c8181fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Sizes of M_H.1, $142load_attr.66 do not match on /tmp/ipykernel_132458/418937865.py (13)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m W_HX_2, W_YH_2, M_H_2, M_Y_2, D1_2, D2_2 \u001b[38;5;241m=\u001b[39m \u001b[43mupdate_weights_jit_parallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_current\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW_HX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW_YH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mM_H\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mM_Y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMUS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmuD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mLayerMinimumGains\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mLayerMaximumGains\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Sizes of M_H.1, $142load_attr.66 do not match on /tmp/ipykernel_132458/418937865.py (13)"
     ]
    }
   ],
   "source": [
    "W_HX_2, W_YH_2, M_H_2, M_Y_2, D1_2, D2_2 = update_weights_jit_parallel(x_current, h, y, zeta, beta, W_HX, W_YH, M_H, M_Y, d1, d2, MUS, muD, np.array(LayerMinimumGains), np.array(LayerMaximumGains) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6832410b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit update_weights_jit_parallel(x_current, h, y, zeta, beta, W_HX, W_YH, M_H, M_Y, d1, d2, MUS, muD , np.array(LayerMinimumGains), np.array(LayerMaximumGains) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553afe64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda29fba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b3693a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def update_weights_jit(x_current, h, y, zeta, beta, W_HX, W_YH, M_H, M_Y, D1, D2, MUS, muD, LayerMinimumGains, LayerMaximumGains):\n",
    "    M_H = (1 - MUS) * M_H + MUS * np.outer(h,h)\n",
    "    W_HX = (1 - MUS) * W_HX + MUS * np.outer(h,x_current)\n",
    "\n",
    "    M_Y = (1 - MUS) * M_Y + MUS * np.outer(y,y)\n",
    "    W_YH = (1 - MUS) * W_YH + MUS * np.outer(y,h)\n",
    "\n",
    "    D1derivative = (1 - zeta) * beta * (np.sum((np.abs(M_H)**2) * D1.T,axis=1) - np.sum(np.abs(W_HX)**2,axis=1)).reshape(-1,1)  + zeta * (1/D1)#+ zeta * self.dlogdet(D1)\n",
    "    D1 = D1 - muD[0] * D1derivative\n",
    "    D1 = np.clip(D1, LayerMinimumGains[0], LayerMaximumGains[0])\n",
    "    D2derivative = (1 - zeta) * (1 - beta) * (np.sum((np.abs(M_Y)**2) * D2.T,axis=1) - np.sum(np.abs(W_YH)**2,axis=1)).reshape(-1,1)  + zeta * (1/D2)#+ zeta * self.dlogdet(D2)\n",
    "    D2 = D2 - muD[1] * D2derivative\n",
    "    D2 = np.clip(D2, LayerMinimumGains[1], LayerMaximumGains[1])\n",
    "    return W_HX, W_YH, M_H, M_Y, D1, D2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c81a9d51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.75, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "        [0.  , 0.75, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "        [0.  , 0.  , 0.75, 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "        [0.  , 0.  , 0.  , 0.75, 0.  , 0.  , 0.  , 0.  ]]),\n",
       " array([[0.75, 0.  , 0.  , 0.  ],\n",
       "        [0.  , 0.75, 0.  , 0.  ],\n",
       "        [0.  , 0.  , 0.75, 0.  ],\n",
       "        [0.  , 0.  , 0.  , 0.75]]),\n",
       " array([[1.5, 0. , 0. , 0. ],\n",
       "        [0. , 1.5, 0. , 0. ],\n",
       "        [0. , 0. , 1.5, 0. ],\n",
       "        [0. , 0. , 0. , 1.5]]),\n",
       " array([[0.75, 0.  , 0.  , 0.  ],\n",
       "        [0.  , 0.75, 0.  , 0.  ],\n",
       "        [0.  , 0.  , 0.75, 0.  ],\n",
       "        [0.  , 0.  , 0.  , 0.75]]),\n",
       " array([[0.2],\n",
       "        [0.2],\n",
       "        [0.2],\n",
       "        [0.2]]),\n",
       " array([[0.99999],\n",
       "        [0.99999],\n",
       "        [0.99999],\n",
       "        [0.99999]]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update_weights_jit(x_current, h, y, zeta, beta, W_HX, W_YH, M_H, M_Y, d1, d2, MUS, muD, np.array(LayerMinimumGains), np.array(LayerMaximumGains) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "522bb999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(LayerMinimumGains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8287a131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19.67390079,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        , 19.67390079,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        , 19.67390079,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , 19.67390079]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.dlogdet(D1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "de1d4df1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19.67392014],\n",
       "       [19.67392014],\n",
       "       [19.67392014],\n",
       "       [19.67392014]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9b052518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "01d686c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "R = np.random.randn(4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d030922d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5625, 0.5625, 0.5625, 0.5625])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.abs(W_HX)**2,axis=1)#**(1./2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "70e90f0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (4,4) (4,8) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [107]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m np\u001b[38;5;241m.\u001b[39msum(\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mR\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43md1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mW_HX\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m,axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (4,4) (4,8) "
     ]
    }
   ],
   "source": [
    "np.sum((np.abs(R)**2) * d1 - np.abs(W_HX)**2,axis=1)#**(1./2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "34f0818c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1143646, 0.       , 0.       , 0.       ],\n",
       "       [0.       , 0.1143646, 0.       , 0.       ],\n",
       "       [0.       , 0.       , 0.1143646, 0.       ],\n",
       "       [0.       , 0.       , 0.       , 0.1143646]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M_H @ D1 @ M_H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "40849844",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = np.diag(D1).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ed050613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05082871, 0.05082871, 0.05082871, 0.05082871]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493ae301",
   "metadata": {},
   "outputs": [],
   "source": [
    "(M_H * d1.T) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0e4e0744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13369857, 0.32637303, 0.67230935, 0.14639678])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((np.abs(R)**2) * d1,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f851a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = np.diag(D1).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d00e9c26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.4481354, -0.4481354, -0.4481354, -0.4481354])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.sum((np.abs(M_H)**2) * d1.T,axis=1) - np.sum(np.abs(W_HX)**2,axis=1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "251c1aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.4481354, -0.4481354, -0.4481354, -0.4481354])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.diag(np.diag(np.diag(M_H @ D1 @ M_H - W_HX @ W_HX.T)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5357dacf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13369857, 0.32637303, 0.67230935, 0.14639678])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.diag(R @ D1 @ R.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "75416796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.60393485, 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 5.39984904, 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 5.16375437, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 3.16234123, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 6.80053786]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddiag(R @ R.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a5bced3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "M_H = (1 - MUS) * M_H + MUS * np.outer(h,h)\n",
    "W_HX = (1 - MUS) * W_HX + MUS * np.outer(h,x_current)\n",
    "\n",
    "M_Y = (1 - MUS) * M_Y + MUS * np.outer(y,y)\n",
    "W_YH = (1 - MUS) * W_YH + MUS * np.outer(y,h)\n",
    "\n",
    "D1derivative = (1 - zeta) * beta * np.diag(np.diag(M_H @ D1 @ M_H - W_HX @ W_HX.T)) #+ zeta * self.dlogdet(D1)\n",
    "D1 = D1 - muD[0] * D1derivative\n",
    "\n",
    "D2derivative = (1 - zeta) * (1 - beta) * np.diag(np.diag(M_Y @ D2 @ M_Y - W_YH @ W_YH.T)) #+ zeta * self.dlogdet(D2)\n",
    "D2 = D2 - muD[1] * D2derivative"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
